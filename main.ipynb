{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63375715-1e2e-4cda-98bb-ae371a3c99e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary\n",
    "\n",
    "# Import your modules\n",
    "from data.data_generator import main as generate_data, load_and_stack_datasets\n",
    "from data.data_loader import load_data, MyDataset\n",
    "from models.model import CustomNN\n",
    "from utils.training import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26a6a2e6-0a8b-4d87-a659-6e3b4345aa6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded:\n",
      "{'input_size': 1851, 'output_size': 1800, 'hidden_layers': 4, 'neurons_per_layer': [3072], 'dropout_prob': 0.0, 'use_batch_norm': False, 'activation': 'leaky_relu', 'learning_rate': 0.0001, 'epochs': 51, 'batch_size': 1024, 'model_save_prefix': './'}\n"
     ]
    }
   ],
   "source": [
    "# Configuration dictionary\n",
    "config = {\n",
    "    'input_size': 1851,\n",
    "    'output_size': 1800,\n",
    "    'hidden_layers': 4,\n",
    "    'neurons_per_layer': [3072],  # Base neuron count; will be repeated hidden_layers times.\n",
    "    'dropout_prob': 0.0,\n",
    "    'use_batch_norm': False,\n",
    "    'activation': 'leaky_relu',\n",
    "    'learning_rate': 1e-4,\n",
    "    'epochs': 51,\n",
    "    'batch_size': 1024,\n",
    "    'model_save_prefix': './'\n",
    "}\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09770ae8-a0c6-4ac4-bf58-ffc3eb52ac09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from data.data_generator import main as generate_data, load_and_stack_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4db20b44-e80b-4e1d-a477-c3199b179579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "<xarray.DataArray 'CG' (nk: 50, time_station: 15310)>\n",
      "array([[ 2.6327693 ,  2.6473465 ,  2.6327693 , ...,  2.6327693 ,\n",
      "         2.6327693 ,  2.6327693 ],\n",
      "       [ 2.3880813 ,  2.3929522 ,  2.3880813 , ...,  2.3880813 ,\n",
      "         2.3880813 ,  2.3880813 ],\n",
      "       [ 2.159401  ,  2.1607904 ,  2.159401  , ...,  2.159401  ,\n",
      "         2.159401  ,  2.159401  ],\n",
      "       ...,\n",
      "       [-0.95191115, -0.95191115, -0.95191115, ..., -0.95191115,\n",
      "        -0.95191115, -0.95191115],\n",
      "       [-0.96208704, -0.96208704, -0.96208704, ..., -0.96208704,\n",
      "        -0.96208704, -0.96208704],\n",
      "       [-0.9715973 , -0.9715973 , -0.9715973 , ..., -0.9715973 ,\n",
      "        -0.9715973 , -0.9715973 ]], dtype=float32)\n",
      "Coordinates:\n",
      "  * time_station  (time_station) object MultiIndex\n",
      "  * time          (time_station) datetime64[ns] 2010-01-03 ... 2010-01-02T12:...\n",
      "  * station       (time_station) int64 21601 32946 31468 ... 29293 36567 38599\n",
      "Dimensions without coordinates: nk\n",
      "<xarray.DataArray 'VA' (nspec: 1800, time_station: 15310)>\n",
      "array([[-0.17477649, -0.17152702, -0.17481678, ..., -0.17459003,\n",
      "        -0.17388287, -0.17480248],\n",
      "       [-0.12029636, -0.11720512, -0.12033236, ..., -0.11977429,\n",
      "        -0.1193355 , -0.12018238],\n",
      "       [-0.08346994, -0.08132066, -0.08348682, ..., -0.08249851,\n",
      "        -0.08283596, -0.0828359 ],\n",
      "       ...,\n",
      "       [-0.96134598, -0.55727091, -0.95729119, ..., -0.94706839,\n",
      "        -0.06213345,  0.29127961],\n",
      "       [-0.96274993, -0.35372975, -0.96152462, ..., -0.93156761,\n",
      "        -0.56307125, -0.04890039],\n",
      "       [-0.96723893, -0.18311839, -0.9671611 , ..., -0.89207197,\n",
      "        -0.85906111, -0.33540517]])\n",
      "Coordinates:\n",
      "  * time_station  (time_station) object MultiIndex\n",
      "  * time          (time_station) datetime64[ns] 2010-01-03 ... 2010-01-02T12:...\n",
      "  * station       (time_station) int64 21601 32946 31468 ... 29293 36567 38599\n",
      "Dimensions without coordinates: nspec\n",
      "<xarray.DataArray 'dpt' (time_station: 15310)>\n",
      "array([-0.17171896, -1.92520588,  0.8574294 , ...,  1.15383428,\n",
      "       -0.0954211 ,  1.59992734])\n",
      "Coordinates:\n",
      "  * time_station  (time_station) object MultiIndex\n",
      "  * time          (time_station) datetime64[ns] 2010-01-03 ... 2010-01-02T12:...\n",
      "  * station       (time_station) int64 21601 32946 31468 ... 29293 36567 38599\n",
      "torch.Size([1800, 15310])\n",
      "torch.Size([1, 15310])\n",
      "torch.Size([50, 15310])\n",
      "torch.Size([1800, 6562])\n",
      "torch.Size([1, 6562])\n",
      "torch.Size([50, 6562])\n",
      "tensor([[-0.1748, -0.1715, -0.1748,  ..., -0.1746, -0.1739, -0.1748],\n",
      "        [-0.1203, -0.1172, -0.1203,  ..., -0.1198, -0.1193, -0.1202],\n",
      "        [-0.0835, -0.0813, -0.0835,  ..., -0.0825, -0.0828, -0.0828],\n",
      "        ...,\n",
      "        [-0.9519, -0.9519, -0.9519,  ..., -0.9519, -0.9519, -0.9519],\n",
      "        [-0.9621, -0.9621, -0.9621,  ..., -0.9621, -0.9621, -0.9621],\n",
      "        [-0.9716, -0.9716, -0.9716,  ..., -0.9716, -0.9716, -0.9716]])\n",
      "Data generation and saving complete.\n",
      "Data generation complete.\n"
     ]
    }
   ],
   "source": [
    "# List of data files (updated names)\n",
    "data_files = [\n",
    "    'data/xtrain_nl2.pt',\n",
    "    'data/ytrain_nl2.pt',\n",
    "    'data/x_valid_nl2.pt',\n",
    "    'data/y_valid_nl2.pt',\n",
    "    'data/norm_data_nl2.nc'\n",
    "]\n",
    "\n",
    "# Check if data files exist; if not, generate them.\n",
    "if not all(os.path.exists(f) for f in data_files):\n",
    "    print(\"Generating data...\")\n",
    "    generate_data()  # This calls your data_generator.py main() function\n",
    "    print(\"Data generation complete.\")\n",
    "else:\n",
    "    print(\"Data already generated. Skipping generation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e340a6cf-9a97-4da0-a764-0f6e87b8e69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and DataLoaders created.\n"
     ]
    }
   ],
   "source": [
    "# Load the data using your data loader module\n",
    "x, y, x_valid, y_valid, norm_data = load_data()\n",
    "\n",
    "# Create dataset objects\n",
    "train_dataset = MyDataset(x, y)\n",
    "valid_dataset = MyDataset(x_valid, y_valid)\n",
    "\n",
    "# Create DataLoaders using the batch size from config\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=False, drop_last=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=config['batch_size'], shuffle=False, drop_last=True)\n",
    "\n",
    "print(\"Data loaded and DataLoaders created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2e61a33-5c33-4360-9a81-b7c96d65d681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1           [-1, 1024, 3072]       5,689,344\n",
      "         LeakyReLU-2           [-1, 1024, 3072]               0\n",
      "            Linear-3           [-1, 1024, 3072]       9,440,256\n",
      "         LeakyReLU-4           [-1, 1024, 3072]               0\n",
      "            Linear-5           [-1, 1024, 3072]       9,440,256\n",
      "         LeakyReLU-6           [-1, 1024, 3072]               0\n",
      "            Linear-7           [-1, 1024, 3072]       9,440,256\n",
      "         LeakyReLU-8           [-1, 1024, 3072]               0\n",
      "            Linear-9           [-1, 1024, 3072]       9,440,256\n",
      "        LeakyReLU-10           [-1, 1024, 3072]               0\n",
      "           Linear-11           [-1, 1024, 1800]       5,531,400\n",
      "================================================================\n",
      "Total params: 48,981,768\n",
      "Trainable params: 48,981,768\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 7.23\n",
      "Forward/backward pass size (MB): 254.06\n",
      "Params size (MB): 186.85\n",
      "Estimated Total Size (MB): 448.14\n",
      "----------------------------------------------------------------\n",
      "Model built on device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Repeat base neuron count by number of hidden layers\n",
    "neurons_list = config['neurons_per_layer'] * config['hidden_layers']\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Build the model using your CustomNN class\n",
    "model = CustomNN(\n",
    "    config['input_size'],\n",
    "    config['output_size'],\n",
    "    config['hidden_layers'],\n",
    "    neurons_list,\n",
    "    config['dropout_prob'],\n",
    "    config['use_batch_norm'],\n",
    "    config['activation']\n",
    ").to(device)\n",
    "\n",
    "# Display model summary\n",
    "summary(model, (config['batch_size'], config['input_size']))\n",
    "print(\"Model built on device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1288747-f18f-40f6-8b20-81d0b53c565a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom loss function defined.\n"
     ]
    }
   ],
   "source": [
    "# Create a normalization tensor from norm_data\n",
    "fac = 1e6\n",
    "a1 = (fac * norm_data['VNL_std'] + 0).transpose().values\n",
    "norm_tensor = torch.FloatTensor(a1).to(device)\n",
    "\n",
    "def criterion(output, target):\n",
    "    return torch.mean(torch.abs(norm_tensor * (target - output)))\n",
    "\n",
    "print(\"Custom loss function defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bdcee1eb-d12a-4a16-bd5d-29a3079eb8e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./L4_3072_'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dynamic model save name using config parameters:\n",
    "model_save_name = f\"{config['model_save_prefix']}L{config['hidden_layers']}_{neurons_list[0]}_\"\n",
    "model_save_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "007b601d-8ab6-488d-882f-d073a2650f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs:  1 / 51\n",
      "Model saved at epoch 5\n",
      "Epochs:  10 / 51\n",
      "Epochs:  20 / 51\n",
      "Epochs:  30 / 51\n",
      "Epochs:  40 / 51\n",
      "Epochs:  50 / 51\n",
      "Training completed in 3.07 seconds\n"
     ]
    }
   ],
   "source": [
    "# Set up the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'], amsgrad=True)\n",
    "\n",
    "# Train the model and record training results\n",
    "start_time = time.time()\n",
    "training_results = train(\n",
    "    model, criterion, train_dataloader, valid_dataloader,\n",
    "    optimizer, config['epochs'], model_save_name, device, save_epochs=[5]\n",
    ")\n",
    "elapsed = time.time() - start_time\n",
    "print(\"Training completed in {:.2f} seconds\".format(elapsed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5e919a3-a7b8-4221-8399-afaffd8e9464",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_name = f\"{config['model_save_prefix']}L{config['hidden_layers']}_{neurons_list[0]}_{config['epochs']}epoch\"\n",
    " \n",
    "# Save training logs\n",
    "np.savetxt(model_save_name + '_tr.txt', np.array(training_results['train_loss']))\n",
    "np.savetxt(model_save_name + '_vd.txt', np.array(training_results['valid_loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f1a43f6-7323-4f3d-bbed-2ceb4cfc0dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "301"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['epochs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a8cc02-1032-4605-a53a-aa18b05967ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pangeo_env",
   "language": "python",
   "name": "pangeo_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
